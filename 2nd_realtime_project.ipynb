{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZkH7muRELRoycXJuPDKMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raka7317/set_project_work/blob/main/2nd_realtime_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch pandas numpy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqJo4UYEfZ60",
        "outputId": "3ca622dd-9762-4f03-de2f-4fe3afd1d8b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 1. IMPORT LIBRARIES\n",
        "# =====================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "# =====================================================\n",
        "# 2. LOAD DATASET (LIMIT TO 50,000)\n",
        "# =====================================================\n",
        "CSV_PATH = \"cleaned_dataset.csv\"   # ♥● CHANGE THIS\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "URL_COL = \"url\"      # ♥● change if needed\n",
        "LABEL_COL = \"labels\"  # ♥● change if needed\n",
        "\n",
        "df = df[[URL_COL, LABEL_COL]].dropna()\n",
        "\n",
        "MAX_SAMPLES = 50000\n",
        "if len(df) > MAX_SAMPLES:\n",
        "    df = df.sample(n=MAX_SAMPLES, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Dataset loaded\")\n",
        "print(\"Total samples used:\", len(df))\n",
        "\n",
        "urls = df[URL_COL].astype(str).tolist()\n",
        "labels = torch.tensor(df[LABEL_COL].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# =====================================================\n",
        "# 3. TRAIN–TEST SPLIT\n",
        "# =====================================================\n",
        "urls_train, urls_test, y_train, y_test = train_test_split(\n",
        "    urls,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(urls_train))\n",
        "print(\"Test size :\", len(urls_test))\n",
        "\n",
        "# =====================================================\n",
        "# 4. CHARACTER TOKENIZER\n",
        "# =====================================================\n",
        "MAX_LEN = 128\n",
        "\n",
        "char2idx = {\"<PAD>\": 0}\n",
        "for url in urls_train:\n",
        "    for ch in url:\n",
        "        if ch not in char2idx:\n",
        "            char2idx[ch] = len(char2idx)\n",
        "\n",
        "def encode_url(url):\n",
        "    seq = [char2idx.get(ch, 0) for ch in url[:MAX_LEN]]\n",
        "    return seq + [0] * (MAX_LEN - len(seq))\n",
        "\n",
        "X_train = torch.tensor([encode_url(u) for u in urls_train], dtype=torch.long)\n",
        "X_test  = torch.tensor([encode_url(u) for u in urls_test], dtype=torch.long)\n",
        "\n",
        "VOCAB_SIZE = len(char2idx)\n",
        "print(\"Vocabulary size:\", VOCAB_SIZE)\n",
        "\n",
        "# =====================================================\n",
        "# 5. TCN + ATTENTION MODEL\n",
        "# =====================================================\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = torch.softmax(self.fc(x), dim=1)\n",
        "        return (weights * x).sum(dim=1)\n",
        "\n",
        "class TCNWithAttention(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 32, padding_idx=0)\n",
        "        self.conv1 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=2, dilation=2)\n",
        "        self.attn = Attention(64)\n",
        "        self.fc = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).transpose(1, 2)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.attn(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "tcn = TCNWithAttention(VOCAB_SIZE).to(device)\n",
        "\n",
        "# =====================================================\n",
        "# 6. TRAIN TCN MODEL\n",
        "# =====================================================\n",
        "optimizer = torch.optim.Adam(tcn.parameters(), lr=0.001)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(\"\\nTraining TCN model...\")\n",
        "for epoch in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    logits = tcn(X_train)\n",
        "    loss = loss_fn(logits, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# =====================================================\n",
        "# 7. GET TCN SCORES\n",
        "# =====================================================\n",
        "tcn.eval()\n",
        "with torch.no_grad():\n",
        "    train_tcn_scores = torch.sigmoid(tcn(X_train)).squeeze()\n",
        "    test_tcn_scores  = torch.sigmoid(tcn(X_test)).squeeze()\n",
        "\n",
        "# =====================================================\n",
        "# 8. TOKEN-BASED FEATURE\n",
        "# =====================================================\n",
        "SUSPICIOUS_TOKENS = [\n",
        "    \"login\", \"verify\", \"secure\",\n",
        "    \"update\", \"account\", \"signin\",\n",
        "    \"confirm\", \"password\"\n",
        "]\n",
        "\n",
        "def token_score(url):\n",
        "    url = url.lower()\n",
        "    count = sum(tok in url for tok in SUSPICIOUS_TOKENS)\n",
        "    return min(count / 3, 1.0)\n",
        "\n",
        "train_token_scores = torch.tensor([token_score(u) for u in urls_train])\n",
        "test_token_scores  = torch.tensor([token_score(u) for u in urls_test])\n",
        "\n",
        "# =====================================================\n",
        "# 9. HYBRID FUSION MLP\n",
        "# =====================================================\n",
        "class HybridMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "fusion = HybridMLP().to(device)\n",
        "\n",
        "# =====================================================\n",
        "# 10. TRAIN HYBRID MODEL\n",
        "# =====================================================\n",
        "fusion_optimizer = torch.optim.Adam(fusion.parameters(), lr=0.01)\n",
        "fusion_loss = nn.BCELoss()\n",
        "\n",
        "train_features = torch.stack(\n",
        "    [train_tcn_scores, train_token_scores], dim=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Hybrid Fusion model...\")\n",
        "for epoch in range(5):\n",
        "    fusion_optimizer.zero_grad()\n",
        "    preds = fusion(train_features)\n",
        "    loss = fusion_loss(preds, y_train)\n",
        "    loss.backward()\n",
        "    fusion_optimizer.step()\n",
        "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# =====================================================\n",
        "# 11. EVALUATION\n",
        "# =====================================================\n",
        "fusion.eval()\n",
        "with torch.no_grad():\n",
        "    test_features = torch.stack(\n",
        "        [test_tcn_scores, test_token_scores], dim=1\n",
        "    )\n",
        "    final_preds = fusion(test_features).squeeze()\n",
        "\n",
        "y_pred = (final_preds > 0.5).int().numpy()\n",
        "y_true = y_test.int().numpy()\n",
        "\n",
        "print(\"\\n===== FINAL RESULTS (50,000 SAMPLES) =====\")\n",
        "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PaTUT4vgDHL",
        "outputId": "e75d7145-9f5b-4952-8d62-e9e3d84e99c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded\n",
            "Total samples used: 50000\n",
            "Train size: 40000\n",
            "Test size : 10000\n",
            "Vocabulary size: 100\n",
            "\n",
            "Training TCN model...\n",
            "Epoch 1 | Loss: 0.7372\n",
            "Epoch 2 | Loss: 0.7151\n",
            "Epoch 3 | Loss: 0.6936\n",
            "Epoch 4 | Loss: 0.6723\n",
            "Epoch 5 | Loss: 0.6507\n",
            "\n",
            "Training Hybrid Fusion model...\n",
            "Epoch 1 | Loss: 0.5781\n",
            "Epoch 2 | Loss: 0.5687\n",
            "Epoch 3 | Loss: 0.5595\n",
            "Epoch 4 | Loss: 0.5505\n",
            "Epoch 5 | Loss: 0.5417\n",
            "\n",
            "===== FINAL RESULTS (50,000 SAMPLES) =====\n",
            "Accuracy : 0.9249\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}